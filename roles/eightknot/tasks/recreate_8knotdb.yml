- name: Load aws variables
  ansible.builtin.include_vars:
    file: ../../aws/vars/main.yml

- name: test aws credentials
  ansible.builtin.include_role:
    name: aws
    tasks_from: check_saml

- name: gather AWS EC2 metadata facts
  amazon.aws.ec2_metadata_facts:

- name: Gather snapshot info from AWS
  amazon.aws.ec2_snapshot_info:
    filters:
      owner-id: "{{ aws_account_id }}"
      # "tag:createdby": ansible
      "tag:Project": PostgresMigration
    profile: "{{ aws_auth_profile }}"
    region: "{{ aws_region }}"
  register: snapshot_lookup_results
  delegate_to: localhost

- name: Determine the most recent snapshot created for this project
  set_fact:
    latest_snapshot: "{{ snapshot_lookup_results.snapshots | sort(attribute='start_time', reverse=true) | first }}"

- debug:
    var: latest_snapshot.snapshot_id

- name: Fail if progress is not 100% on the snapshot
  ansible.builtin.fail:
    msg: >
      Snapshot creation progress for snapshot {{ latest_snapshot.snapshot_id }} is not at 100%.
      Actual progress: {{ latest_snapshot.progress }}.
  when: latest_snapshot.progress != "100%"

- name: Gather volume info from AWS
  amazon.aws.ec2_vol_info:
    filters:
      # owner id is implied - i dont think volumes can be public like snapshots
      # "tag:createdby": ansible
      "tag:Project": PostgresMigration
    profile: "{{ aws_auth_profile }}"
    region: "{{ aws_region }}"
  register: volume_lookup_results
  delegate_to: localhost

- name: Determine the most recent volume created for this project
  set_fact:
    latest_volume: "{{ volume_lookup_results.volumes | sort(attribute='create_time', reverse=true) | first }}"

- debug:
    var: latest_volume.id

- name: Create new volume from snapshot {{ latest_snapshot.snapshot_id }} (if there isnt a relatively new one available)
  # Creates a new EBS volume based on the snapshot.
  # The size can be increased here if `new_volume_size_gb` is set.
  amazon.aws.ec2_vol:
    snapshot: "{{ latest_snapshot.snapshot_id }}"
    region: "{{ aws_region }}"
    zone: "{{ aws_zone }}"
    volume_type: "{{ new_volume_type }}"
    # size: "{{ new_volume_size_gb if new_volume_size_gb > 0 else omit }}" # Omit size if 0 to keep original
    profile: "{{ aws_auth_profile }}"
    tags:
      Name: "db-clone-{{ ansible_date_time.date }}"
      createdby: ansible
      Project: PostgresMigration
    state: present
  register: new_volume
  delegate_to: localhost
  when: (now(utc=True) - (latest_volume.create_time | to_datetime(iso8601format) )).days > 3
  vars:
    iso8601format: "%Y-%m-%dT%H:%M:%S.%f+00:00"

- name: use newly created volume as latest
  ansible.builtin.set_fact:
    latest_volume: "{{ new_volume.volume }}"
  when: (now(utc=True) - (latest_volume.create_time | to_datetime(iso8601format) )).days > 3
  vars:
    iso8601format: "%Y-%m-%dT%H:%M:%S.%f+00:00"

- name: Bring 8knot down
  include_tasks: down.yml

- name: "Determine block device for {{ mount_point }}"
  block:
    - name: list matching mounts
      ansible.builtin.set_fact:
        mount_point_devices: "{{ ansible_mounts | json_query(query) }}"
      vars:
        query: "[?mount=='{{ mount_point }}'].device"

    - name: "Determine block device for {{ mount_point }}"
      ansible.builtin.set_fact:
        mount_point_block: "{{ mount_point_devices | first }}"
      when: mount_point_devices is defined and (mount_point_devices | length > 0)

    - name: "Determine block device for {{ mount_point }}"
      ansible.builtin.set_fact:
        mount_point_block: "{{ source_device_disk }}"
      when: mount_point_devices is not defined or (mount_point_devices | length == 0)

- name: Identify aws volume mounted at location
  identify_volume:
    partition_device: "{{ mount_point_block }}"
  register: aws_vol

- name: unmount DB from {{ mount_point }}
  ansible.posix.mount:
    path: "{{ mount_point }}"
    state: unmounted
  become: true

- name: Detach old volume {{ aws_vol.aws_volume_id }} from instance {{ ansible_ec2_instance_id }}
  amazon.aws.ec2_vol:
    id: "{{ aws_vol.aws_volume_id }}"
    region: "{{ aws_region }}"
    profile: "{{ aws_auth_profile }}"
    instance: None
  register: detach_volume_result
  delegate_to: localhost
  when: aws_vol.aws_volume_id is defined

- name: Attach new volume {{ latest_volume.id }} to instance {{ ansible_ec2_instance_id }} as {{ mount_point_block }}
  # Attaches the newly created volume to the target EC2 instance.
  amazon.aws.ec2_vol:
    instance: "{{ ansible_ec2_instance_id }}"
    id: "{{ latest_volume.id }}"
    device_name: "/dev/sdb" # Use the same device name or a new one
    region: "{{ aws_region }}"
    profile: "{{ aws_auth_profile }}"
    state: present
  register: attach_volume_result
  delegate_to: localhost

- name: Wait for the new device to be available on the host
  # Waits until the kernel recognizes the newly attached device.
  ansible.builtin.wait_for:
    path: "{{ mount_point_block }}" # This path needs to be the kernel's device path (e.g., /dev/xvdf)
    timeout: 60
    msg: "New device {{ mount_point_block }} did not appear within 60 seconds."

- name: remount the augur db
  include_tasks: mount_augur.yml

# TODO: verify the new mount point matches the new volume ID

# This was done destructively because it also removes the network.
# otherwise docker would consistently fail to come back up with some network error.
# surprised theres no options in the ansible module for this.
- name: destructively take 8knot down
  include_tasks: down-remove.yml

- name: Delete the 8Knot cache volume to clear the cache
  community.docker.docker_volume:
    name: "{{ eightknot_pg_cache_volume_name }}"
    state: absent

- name: Update the postgres config from the clone by copying postgresql.conf
  ansible.builtin.copy:
    src: files/postgresql.conf
    dest: "{{ mount_point }}/postgresql.conf"
    owner: 999
    group: systemd-journal
    mode: "0600"
  become: true

- name: Bring 8knot up
  include_tasks: up.yml

- name: Crash Recovery - register start
  set_fact:
    recovery_start: "{{ now() }}"

- name: Wait for PostgreSQL to start accepting connections
  ansible.builtin.wait_for:
    host: localhost
    port: 5432
    state: started
    delay: 5 # Seconds to wait before starting checks
    timeout: 1500 # Maximum seconds to wait

- name: Crash recovery - register end
  set_fact:
    recovery_end: "{{ now() }}"
# Print debug info, or use the timestamps to calculate whatever you need
- name: Print execution time
  debug:
    msg: "Crash recovery start: {{ recovery_start }}, end: {{ recovery_end }} Duration: ~{{ ((recovery_end | to_datetime) - (recovery_start | to_datetime)).total_seconds() | int }} seconds"

- name: Trigger refresh of materialized views
  ansible.builtin.include_role:
    name: eightknot
    tasks_from: refresh_mat_views

- name: Validate that 8knot is up and serving requests from the public domain
  ansible.builtin.uri:
    url: https://eightknot.osci.io
    method: GET
    # The 'status_code' parameter defaults to 200,
    # but you can be explicit if you want:
    status_code: 200
  register: web_check
  until: web_check.status == 200
  retries: 30 # Total number of retries
  delay: 10 # Seconds to wait between retries
  delegate_to: localhost

- name: Disable Fast Snapshot Restore on all snapshots to save money
  ansible.builtin.include_role:
    name: aws
    tasks_from: disable_fsr

- name: Cleanup old snapshots
  ansible.builtin.include_role:
    name: aws
    tasks_from: cleanup_snapshots.yml

- name: Cleanup old volumes
  ansible.builtin.include_role:
    name: aws
    tasks_from: cleanup_volumes.yml
