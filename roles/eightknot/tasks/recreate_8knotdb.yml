    - name: Create new volume from snapshot {{ snapshot_result.snapshot_id }}
      # Creates a new EBS volume based on the snapshot.
      # The size can be increased here if `new_volume_size_gb` is set.
      community.aws.ec2_vol:
        snapshot_id: "{{ snapshot_result.snapshot_id }}"
        region: "{{ aws_region }}"
        volume_type: "{{ new_volume_type }}"
        size: "{{ new_volume_size_gb if new_volume_size_gb > 0 else omit }}" # Omit size if 0 to keep original
        tags:
          Name: "{{ new_pg_container_name }}-data-volume"
          Project: "PostgresMigration"
        state: present
      register: new_volume_result # Stores the new volume details
      delegate_to: localhost

    # - name: Delete the snapshot ({{ new_volume_result.snapshot_id }}) after volume creation
    #   # This task removes the EBS snapshot immediately after a new volume has been successfully
    #   # created from it. It relies on the 'new_volume_result' variable which should be
    #   # registered from the 'Create new volume from snapshot' task.
    #   #
    #   # CAUTION: Deleting snapshots means you lose that specific point-in-time recovery point.
    #   # Ensure this is the desired behavior for your workflow.
    #   community.aws.ec2_snapshot:
    #     snapshot_id: "{{ new_volume_result.snapshot_id }}"
    #     region: "{{ aws_region }}"
    #     state: absent
    #   delegate_to: localhost
    #   # ensures this task only runs if the 'new_volume_result'
    #   # variable (from the volume creation task) contains a valid snapshot ID.
    #   when: new_volume_result.snapshot_id is defined and new_volume_result.snapshot_id != ''

    - name: Attach new volume {{ new_volume_result.volume_id }} to instance {{ target_instance_id }} as {{ source_device_disk }}
      # Attaches the newly created volume to the target EC2 instance.
      community.aws.ec2_vol:
        instance: "{{ target_instance_id }}"
        id: "{{ new_volume_result.volume_id }}"
        device_name: "{{ source_device_disk }}" # Use the same device name or a new one
        region: "{{ aws_region }}"
        state: present
      register: attach_volume_result
      delegate_to: localhost

    - name: Wait for the new device to be available on the host
      # Waits until the kernel recognizes the newly attached device.
      ansible.builtin.wait_for:
        path: "{{ source_device_partition }}" # This path needs to be the kernel's device path (e.g., /dev/xvdf)
        timeout: 60
        msg: "New device {{ source_device_partition }} did not appear within 60 seconds."

    - name: Create mount point directory ({{ mount_point }}) if it doesn't exist
      # Ensures the directory where the volume will be mounted exists.
      ansible.builtin.file:
        path: "{{ mount_point }}"
        state: directory
        mode: '0755'

    - name: Mount new volume ({{ source_device_partition }}) to {{ mount_point }}
      # Mounts the new EBS volume to the specified directory.
      # Ensure `fstype` matches the filesystem on your volume.
      ansible.builtin.mount:
        src: "{{ source_device_partition }}" # The actual device path on the target OS
        path: "{{ mount_point }}"
        fstype: "ext4" # Adjust filesystem type (e.g., xfs, ext4)
        state: mounted

    - name: Start new PostgreSQL Docker container ({{ new_pg_container_name }})
      # Starts a new PostgreSQL Docker container, pointing its data volume to the newly mounted EBS volume.
      community.docker.docker_container:
        name: "{{ new_pg_container_name }}"
        image: "{{ pg_image }}:{{ pg_version }}"
        state: started
        restart_policy: always
        env:
          POSTGRES_PASSWORD: "{{ pg_password }}" # Pass PostgreSQL password
        volumes:
          - "{{ mount_point }}:/var/lib/postgresql/data" # Mount the new volume as PostgreSQL data directory
        ports:
          - "5432:5432" # Expose PostgreSQL port. Adjust if old container used it or if you need a different port.
      register: new_pg_container_start

    - name: Wait for new PostgreSQL container to be healthy
      # Waits for the PostgreSQL service inside the container to become reachable on port 5432.
      ansible.builtin.wait_for:
        port: 5432
        host: "{{ ansible_host }}" # Connects to the target server's IP
        delay: 5 # Wait 5 seconds before first check
        timeout: 120 # Timeout after 120 seconds
        state: started
        msg: "PostgreSQL container did not become healthy on port 5432."

    - name: Verify that the new PostgreSQL is running and taking requests
      # Executes a simple `psql` command inside the new container to verify connectivity.
      ansible.builtin.shell: |
        docker exec {{ new_pg_container_name }} psql -U postgres -c "SELECT 1;"
      environment:
        PGPASSWORD: "{{ pg_password }}" # Pass password via environment variable for psql
      register: pg_check_result
      failed_when: "'(1 row)' not in pg_check_result.stdout" # Fails if '1 row' is not found in output
      changed_when: false # This task is for verification, not for changing state
      until: pg_check_result is not failed # Retry until successful
      retries: 5
      delay: 10
      # You can add more robust verification steps here, e.g., querying specific data.

    # - name: Unmount and delete old volume ({{ source_volume_id }})
    #   # CAUTION: This step permanently deletes your old volume.
    #   # ONLY run this AFTER you have thoroughly verified that the new PostgreSQL
    #   # instance is fully functional and data is correct.
    #   # Consider commenting this out or running it manually after verification.
    #   community.aws.ec2_vol:
    #     id: "{{ source_volume_id }}"
    #     region: "{{ aws_region }}"
    #     state: absent
    #   delegate_to: localhost
    #   #only delete if the new container was started and the PostgreSQL verification command succeeded.
    #   when: new_pg_container_start.changed and pg_check_result.rc == 0

    # - name: Delete the snapshot ({{ snapshot_result.snapshot_id }})
    #   # CAUTION: This step permanently deletes the snapshot.
    #   # Keep the snapshot as a recovery point until you are absolutely certain
    #   # the new setup is stable and you no longer need it.
    #   community.aws.ec2_snapshot:
    #     snapshot_id: "{{ snapshot_result.snapshot_id }}"
    #     region: "{{ aws_region }}"
    #     state: absent
    #   delegate_to: localhost
    #   # only delete if the new container was started and the PostgreSQL verification command succeeded.
    #   when: new_pg_container_start.changed and pg_check_result.rc == 0
