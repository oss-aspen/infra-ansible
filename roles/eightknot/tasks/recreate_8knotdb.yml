- name: Load aws variables
  ansible.builtin.include_vars:
    file: ../../aws/vars/main.yml

- name: test aws credentials
  ansible.builtin.include_role:
    name: aws
    tasks_from: check_saml

- name: gather AWS EC2 metadata facts
  amazon.aws.ec2_metadata_facts:

- name: Gather snapshot info from AWS
  amazon.aws.ec2_snapshot_info:
    filters:
      owner-id: "{{ aws_account_id }}"
      # "tag:createdby": ansible
      "tag:Project": PostgresMigration
    profile: "{{ aws_auth_profile }}"
    region: "{{ aws_region }}"
  register: snapshot_lookup_results
  delegate_to: localhost

- name: Determine the most recent snapshot created for this project
  set_fact:
    latest_snapshot: "{{ snapshot_lookup_results.snapshots | sort(attribute='start_time', reverse=true) | first }}"

- name: Fail if progress is not 100% on the snapshot
  ansible.builtin.fail:
    msg: >
      Snapshot creation progress for snapshot {{ latest_snapshot.snapshot_id }} is not at 100%.
      Actual progress: {{ latest_snapshot.progress }}.
  when: latest_snapshot.progress != "100%"

- name: Gather volume info from AWS
  amazon.aws.ec2_vol_info:
    filters:
      # owner id is implied - i dont think volumes can be public like snapshots
      # "tag:createdby": ansible
      "tag:Project": PostgresMigration
    profile: "{{ aws_auth_profile }}"
    region: "{{ aws_region }}"
  register: volume_lookup_results
  delegate_to: localhost

- name: Determine the most recent volume created for this project
  set_fact:
    latest_volume: "{{ volume_lookup_results.volumes | sort(attribute='create_time', reverse=true) | first }}"

- name: Create new volume from snapshot {{ latest_snapshot.snapshot_id }} (if there isnt a relatively new one available)
  # Creates a new EBS volume based on the snapshot.
  # The size can be increased here if `new_volume_size_gb` is set.
  amazon.aws.ec2_vol:
    snapshot: "{{ latest_snapshot.snapshot_id }}"
    region: "{{ aws_region }}"
    zone: "{{ aws_zone }}"
    volume_type: "{{ new_volume_type }}"
    # size: "{{ new_volume_size_gb if new_volume_size_gb > 0 else omit }}" # Omit size if 0 to keep original
    profile: "{{ aws_auth_profile }}"
    tags:
      Name: "db-clone-{{ ansible_date_time.date }}"
      createdby: ansible
      Project: PostgresMigration
    state: present
  register: new_volume
  delegate_to: localhost
  when: (now(utc=True) - (latest_volume.create_time | to_datetime(iso8601format) )).days > 3
  vars:
    iso8601format: '%Y-%m-%dT%H:%M:%S.%f+00:00'
  
- name: use newly created volume as latest
  ansible.builtin.set_fact:
    latest_volume: "{{ new_volume.volume }}"
  when: (now(utc=True) - (latest_volume.create_time | to_datetime(iso8601format) )).days > 3
  vars:
    iso8601format: '%Y-%m-%dT%H:%M:%S.%f+00:00'

- name: Bring 8knot down
  include_tasks: down.yml

- name: "Determine block device for {{ mount_point }}"
  block:
    - name: list matching mounts
      ansible.builtin.set_fact:
        mount_point_devices: "{{ ansible_mounts | json_query(query) }}"
      vars:
        query: "[?mount=='{{ mount_point }}'].device"

    - name: "Determine block device for {{ mount_point }}"
      ansible.builtin.set_fact:
        mount_point_block: "{{ mount_point_devices | first }}"
      when: mount_point_devices is defined and (mount_point_devices | length > 0)

    - name: "Determine block device for {{ mount_point }}"
      ansible.builtin.set_fact:
        mount_point_block: "{{ source_device_disk }}"
      when: mount_point_devices is not defined or (mount_point_devices | length == 0)

- name: Identify aws volume mounted at location
  identify_volume:
    partition_device: "{{ mount_point_block }}"
  register: aws_vol

- name: unmount DB from {{ mount_point }}
  ansible.posix.mount:
    path: "{{ mount_point }}"
    state: unmounted
  become: true

- name: Detach old volume {{ aws_vol.aws_volume_id }} from instance {{ ansible_ec2_instance_id }}
  amazon.aws.ec2_vol:
    id: "{{ aws_vol.aws_volume_id }}"
    region: "{{ aws_region }}"
    profile: "{{ aws_auth_profile }}"
    state: absent
  register: detach_volume_result
  delegate_to: localhost
  when: aws_vol.aws_volume_id is defined

- name: Attach new volume {{ latest_volume.id }} to instance {{ ansible_ec2_instance_id }} as {{ mount_point_block }}
  # Attaches the newly created volume to the target EC2 instance.
  amazon.aws.ec2_vol:
    instance: "{{ ansible_ec2_instance_id }}"
    id: "{{ latest_volume.id }}"
    device_name: "/dev/sdb" # Use the same device name or a new one
    region: "{{ aws_region }}"
    profile: "{{ aws_auth_profile }}"
    state: present
  register: attach_volume_result
  delegate_to: localhost

- name: Wait for the new device to be available on the host
  # Waits until the kernel recognizes the newly attached device.
  ansible.builtin.wait_for:
    path: "{{ mount_point_block }}" # This path needs to be the kernel's device path (e.g., /dev/xvdf)
    timeout: 60
    msg: "New device {{ mount_point_block }} did not appear within 60 seconds."

- name: remount the augur db
  include_tasks: mount_augur.yml

# TODO: verify the new mount point matches the new volume ID

- name: Delete the 8Knot cache volume to clear the cache
  community.docker.docker_volume:
    name: "{{ eightknot_pg_cache_volume_name }}"
    state: absent

- name: Bring 8knot up
  include_tasks: up.yml



# - name: Disable Fast Snapshot Restore on all snapshots to save money
#   ansible.builtin.include_role:
#     name: aws
#     tasks_from: disable_fsr

# - name: Cleanup old snapshots
#   ansible.builtin.include_role:
#     name: aws
#     tasks_from: cleanup_snapshots.yml

# - name: Cleanup old volumes
#   ansible.builtin.include_role:
#     name: aws
#     tasks_from: cleanup_volumes.yml